{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlecolab = False\n",
    "\n",
    "if googlecolab:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "    !pip install Pillow==4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperpameters\n",
    "\n",
    "Define the hyperparameters. You can play with those later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loading\n",
    "\n",
    "workers = 0 # Number of workers for dataloader (/!\\ set to 4 when you're done debugging)\n",
    "\n",
    "## Architecture\n",
    "\n",
    "nz = 100 # Size of z latent vector (i.e. size of generator input)\n",
    "ndf = 32 # Base size of feature maps in discriminator\n",
    "ngf = 32 # Base size of feature maps in generator\n",
    "\n",
    "## Optimization\n",
    "\n",
    "lrD = 0.0002 # Learning rate for the discriminator\n",
    "lrG = 0.0002 # Learning rate for the generator\n",
    "beta1G = 0.5 # Momentum beta1 for the discriminator\n",
    "beta1D = 0.5 # Momentum beta1 for the generator\n",
    "\n",
    "## Training\n",
    "\n",
    "batch_size = 256 # Images per batch\n",
    "nb_update_D = 1 # Number of sub-steps of discriminator optim. at each step\n",
    "nb_update_G = 1 # Number of sub-steps of generator optim. at each step\n",
    "steps = 8000 # Number of global steps in the training loop\n",
    "nb_epochs = None # Number of epochs, leave \"None\" if you want to set the number of \"steps\" (i.e. batches)\n",
    "\n",
    "\n",
    "if nb_epochs is None:\n",
    "    nb_epochs = (steps * batch_size) / (nb_update_D * 202000)\n",
    "else:\n",
    "    steps = int(nb_epochs * nb_update_D * 202000 / batch_size)\n",
    "print(\"Doing %.1f epochs in %d steps\" % (nb_epochs, steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Download and load the dataset. Nothing to do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Dataset loading\n",
    "\n",
    "if ! [ -d \"/tmp/celeba/img_align_celeba\" ] ; then\n",
    "    mkdir /tmp/celeba\n",
    "    cd /tmp/celeba\n",
    "    wget http://webia.lip6.fr/~robert/cours/rdfia/celeba.zip\n",
    "    unzip celeba.zip\n",
    "fi\n",
    "\n",
    "# For 64x64 images, replace celeba with celeba64 everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=\"/tmp/celeba\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architectures\n",
    "\n",
    "## Discriminator\n",
    "\n",
    "Input: Image $x \\in \\mathbb{R}^{32\\times 32\\times 3}$  \n",
    "Output: \"Real\" image probability $\\in [0,1]$\n",
    "\n",
    "* Convolution (`1*ndf` filters, kernel 4, stride 2, padding 1, no bias)\n",
    "* Batch Norm 2D\n",
    "* LeakyReLU ($\\alpha = 0.2$)\n",
    "* Convolution (`2*ndf` filters, kernel 4, stride 2, padding 1, no bias)\n",
    "* Batch Norm 2D\n",
    "* LeakyReLU ($\\alpha = 0.2$)\n",
    "* Convolution (`4*ndf` filters, kernel 4, stride 2, padding 1, no bias)\n",
    "* Batch Norm 2D\n",
    "* LeakyReLU ($\\alpha = 0.2$)\n",
    "* Convolution (1 filter, kernel 4, stride 1, padding 0, no bias)\n",
    "* Sigmoid activation\n",
    "\n",
    "## Generator\n",
    "\n",
    "Input: Random \"noise\" $z \\in \\mathbb{R}^{\\text{nz}}$  \n",
    "Output: Generated image $\\tilde x \\in \\mathbb{R}^{32\\times 32\\times 3}$\n",
    "\n",
    "* Convolution Transpose (`4*ngf` filters, kernel 4, stride 1, padding 0, no bias)\n",
    "* Batch Norm 2D\n",
    "* ReLU\n",
    "* Convolution Transpose (`2*ngf` filters, kernel 4, stride 2, padding 1, no bias)\n",
    "* Batch Norm 2D\n",
    "* ReLU\n",
    "* Convolution Transpose (`1*ngf` filters, kernel 4, stride 2, padding 1, no bias)\n",
    "* Batch Norm 2D\n",
    "* ReLU\n",
    "* Convolution Transpose (3 filters, kernel 4, stride 2, padding 1, no bias)\n",
    "* Tanh activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # TODO\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # TODO\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the models\n",
    "print(netG)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test you models to check if they \n",
    "z = torch.zeros(10, nz, 1, 1).to(device)\n",
    "x = torch.zeros(10, 3, 32, 32).to(device)\n",
    "print(netG(z).shape) # expected: [10, 3, 32, 32]\n",
    "print(netD(x).shape) # expected: [10, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and training\n",
    "\n",
    "Here we will define:\n",
    "* Our prior $P(z)$ that we use to sample random \"noise\". We will use a Gaussian distribution.\n",
    "* The criterion that will be used to train the discriminator, and indirectly the generator. We will use the binary cross-entropy.\n",
    "* The optimizers of both models. We will use the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior P(z). Returns a Gaussian random tensor of shape (batch_size, nz, 1, 1)\n",
    "def get_noise(batch_size):\n",
    "    noise = None # TODO\n",
    "    return noise.to(device)\n",
    "\n",
    "# Create the criterion function that will take (y_hat, y) as input\n",
    "criterion = None # TODO\n",
    "\n",
    "# Setup Adam optimizers for D and G\n",
    "optimizerD = None # TODO, take netD.parameters(), use the right lr and beta1\n",
    "optimizerG = None # TODO, same for G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format / batch creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data format / batch creation functions\n",
    "\n",
    "fixed_noise = get_noise(196) # Create a fixed random vector sampled from a Gaussian, will be used during train for viz\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "iterator = iter(dataloader)\n",
    "\n",
    "# returns a batch of real images from the dataset (iterates infinitely on the dataset)\n",
    "def get_batch_real():\n",
    "    global iterator\n",
    "    try:\n",
    "        x_real = next(iterator)[0].to(device)\n",
    "    except:\n",
    "        iterator = iter(dataloader)\n",
    "        x_real = next(iterator)[0].to(device)\n",
    "    y_real = torch.full((x_real.size(0),), real_label, device=device)\n",
    "    return x_real, y_real\n",
    "\n",
    "# TODO\n",
    "# returns a batch of generated images and training targets y_fake\n",
    "# Note that the targets y_fake will be different is train_G is True or False\n",
    "def get_batch_fake(train_G=False):\n",
    "    z = get_noise(batch_size)\n",
    "    x_fake = None # TODO generate images from z\n",
    "    y_fake = None # TODO create targets, depends on train_G\n",
    "    return x_fake, y_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "**Reminder:** when your training loop starts to work, change the `workers` variable to 4 and rerun your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(steps):\n",
    "    \n",
    "    ########\n",
    "    # Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "    for _ in range(nb_update_D):\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        # Create batches\n",
    "        x_real, y_real = get_batch_real()\n",
    "        x_fake, y_fake = get_batch_fake()\n",
    "        \n",
    "        # Forward \n",
    "        y_hat_real = None # TODO\n",
    "        y_hat_fake = None # TODO\n",
    "        errD = None       # TODO sum of criterion of real and fake samples\n",
    "        \n",
    "        # Backward\n",
    "        # TODO backward & optimization step on D\n",
    "        \n",
    "        # Compute / save metrics\n",
    "        avg_output_for_real = y_hat_real.mean().item()\n",
    "        avg_output_for_fake = y_hat_fake.mean().item()    \n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "\n",
    "\n",
    "    ########\n",
    "    # Update G network: maximize log(D(G(z)))\n",
    "    for _ in range(nb_update_G):\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # TODO: forward + backward\n",
    "        # NOTE: use errG as name for your loss variable, like errD above\n",
    "        \n",
    "        # Compute / save metrics\n",
    "        G_losses.append(errG.item())\n",
    "        \n",
    "    \n",
    "    ########\n",
    "    # Logs\n",
    "    if i % 25 == 0:\n",
    "        print('[%5d/%5d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
    "              % (i, steps, errD.item(), errG.item(), avg_output_for_real, avg_output_for_fake))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            x_fake = netG(fixed_noise).detach().cpu()\n",
    "        img_list.append(vutils.make_grid(x_fake, padding=2, normalize=True, nrow=14))\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display training evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show generations\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss evolution\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.title(\"Generator Trainig Loss\")\n",
    "plt.plot(G_losses)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"Generator Trainig Loss\")\n",
    "plt.plot(D_losses)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
